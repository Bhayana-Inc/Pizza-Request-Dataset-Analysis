{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5d0d1a-2088-4609-bf77-22a7c8ab5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3133b741-cd32-4aa3-a505-3f2184c1686a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5671, 33)\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(\"./pizza_request_dataset.json\", 'r', 'utf-8') as myFile:\n",
    "    content = myFile.read()\n",
    "pizzaDataset = json.loads(content)\n",
    "df = pd.DataFrame(pizzaDataset)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0813f7f6-0291-4183-92a7-892dafdf9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5671, 34)\n"
     ]
    }
   ],
   "source": [
    "df['requester_received_pizza_int'] = [1 if x else 0 for x in df['requester_received_pizza']]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f29f18-d8c0-4f2e-8bac-f674c96510d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "SIZE=0.1\n",
    "y = df['requester_received_pizza'].astype(int)\n",
    "STRATIFY = df['requester_received_pizza'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d242dfd-d896-486f-a3b4-fae001331bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "def data_preprocessing(text_sentence):\n",
    "    if not isinstance(text_sentence, str):\n",
    "        return \"\"\n",
    "    text_sentence = text_sentence.lower() \n",
    "    text_sentence = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text_sentence)\n",
    "    text_sentence = re.sub(r\"[^a-z\\s'-]\", \"\", text_sentence)\n",
    "    tokens = re.findall(r\"\\b[a-z]+(?:['-][a-z]+)*\\b\", text_sentence) \n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(tokens)\n",
    "df[\"cleaned_data\"] = df[\"request_text_edit_aware\"].apply(data_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d021ebfe-f18f-47a4-bfa7-c4d1269adc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model_number, y_test,pred,prob, tn, fp):\n",
    "    print( modelnumber, 'accuracy', accuracy_score(y_test, pred), \n",
    "      'precision', precision_score(y_test, pred),\n",
    "      'recall', recall_score(y_test, pred),\n",
    "      'F1', f1_score(y_test, pred),\n",
    "      'specificity', tn / (tn + fp),\n",
    "      'AUC', roc_auc_score(y_test, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e475167a-7b54-4136-90c5-c7494e7ff8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_1\n",
    "X = df['request_text'].fillna('')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=SIZE, random_state=SEED, stratify=STRATIFY)\n",
    "unigram = CountVectorizer(ngram_range=(1, 1), max_features=500, lowercase=True, stop_words='english')\n",
    "bigram = CountVectorizer(ngram_range=(2, 2), max_features=500, lowercase=True, stop_words='english')\n",
    "vect = FeatureUnion([('unigram',unigram), ('bigram',bigram)])\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test  = vect.transform(X_test)\n",
    "model_1 = SVC(kernel='linear', probability=True, random_state=SEED).fit(X_train, y_train)\n",
    "pred = model_1.predict(X_test)\n",
    "prob = model_1.predict_proba(X_test)[:,1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e1fe87-2ffd-4df1-a5b7-7407ad34513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 accuracy 0.7306338028169014 precision 0.410958904109589 recall 0.21428571428571427 F1 0.28169014084507044 specificity 0.8995327102803738 AUC 0.5884846461949266\n"
     ]
    }
   ],
   "source": [
    "modelnumber='Model_1'\n",
    "print_results(modelnumber, y_test,pred,prob, tn, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55f1df3-9ade-4788-ad2e-e458641f642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_2\n",
    "activity = [\n",
    "    'post_was_edited',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_account_age_in_days_at_retrieval',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_retrieval',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_comments_at_retrieval',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_retrieval',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_posts_at_retrieval',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_retrieval',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "]\n",
    "reputation = [\n",
    "    'number_of_downvotes_of_request_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_retrieval',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_retrieval',\n",
    "]\n",
    "features= activity+reputation\n",
    "X = df[features].fillna(0).astype(float)\n",
    "X['post_was_edited'] = X['post_was_edited'].astype(int)\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=SIZE, random_state=SEED, stratify=STRATIFY)\n",
    "model_2 = make_pipeline( StandardScaler(),\n",
    "    SVC(kernel='linear', probability=True, random_state=SEED)).fit(X_train, y_train)\n",
    "pred = model_2.predict(X_test)\n",
    "prob = model_2.predict_proba(X_test)[:,1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7774331-fd52-4fb8-beeb-dc1d7a57cc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2 accuracy 0.8345070422535211 precision 0.7804878048780488 recall 0.45714285714285713 F1 0.5765765765765766 specificity 0.9579439252336449 AUC 0.7839953271028038\n"
     ]
    }
   ],
   "source": [
    "modelnumber='Model_2'\n",
    "print_results(modelnumber, y_test,pred,prob, tn, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f731d6ab-b45a-4d31-8d85-88b85e5adf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_3\n",
    "narrative = [\"desire\", \"family\", \"job\", \"money\", \"student\"]\n",
    "narratives = {}\n",
    "for nar in narrative:\n",
    "    terms = set()\n",
    "    for term in Path(\"narratives\", f\"{nar}.txt\").read_text().splitlines():\n",
    "        if term.strip():\n",
    "            terms.add(term.strip().lower())\n",
    "    narratives[nar] = terms\n",
    "\n",
    "def narrative_toVector(text: str) -> np.ndarray:\n",
    "    words = text.lower().split()\n",
    "    num_words = len(words) or 1\n",
    "    results = []\n",
    "    for nar in narrative:\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            if word in narratives[nar]:\n",
    "                count += 1\n",
    "        results.append(count / num_words)\n",
    "    return np.array(results)\n",
    "\n",
    "X = np.array([narrative_toVector(t) for t in df['request_text'].fillna('')])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=SIZE, random_state=SEED, stratify=STRATIFY)\n",
    "model_3 = make_pipeline( StandardScaler(),\n",
    "    SVC(kernel='linear', probability=True, random_state=SEED)).fit(X_train, y_train)\n",
    "pred = model_3.predict(X_test)\n",
    "prob = model_3.predict_proba(X_test)[:,1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a962dfc-7f8a-492c-a6d3-b2920b8d7bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3 accuracy 0.7535211267605634 precision 0.0 recall 0.0 F1 0.0 specificity 1.0 AUC 0.5231642189586114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "modelnumber='Model_3'\n",
    "print_results(modelnumber, y_test,pred,prob, tn, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d699199-372d-49c7-961f-8c2d6201baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_4\n",
    "def map_dic(id_str):\n",
    "    try: dic_id = int(id_str)\n",
    "    except ValueError: return None\n",
    "    if 1 <= dic_id <= 2: return 'care'\n",
    "    if 5 <= dic_id <= 6: return 'loyalty'\n",
    "    if 7 <= dic_id <= 8: return 'authority'\n",
    "    if 9 <= dic_id <= 10: return 'sanctity'\n",
    "    else: return None\n",
    "        \n",
    "dims = ['care', 'loyalty', 'authority', 'sanctity']\n",
    "dim_dic = {dim: [] for dim in dims}\n",
    "with Path('MoralFoundations.dic').open(encoding='utf-8') as dic:\n",
    "    line = dic.readline() \n",
    "    while line:\n",
    "        line = line.strip()\n",
    "        if not line or line[0] in {'#', '%'} or len(re.split(r'\\s+', line)) < 2:\n",
    "            line = dic.readline()\n",
    "            continue\n",
    "        tokens = re.split(r'\\s+', line)\n",
    "        for dic_id in tokens[1:]:\n",
    "            dim = map_dic(dic_id)\n",
    "            if dim:\n",
    "                dim_dic[dim].append(tokens[0].replace('*', r'\\w*'))\n",
    "        line = dic.readline()  \n",
    "        \n",
    "patterns = {}        \n",
    "for key, val in dim_dic.items():\n",
    "    if terms:\n",
    "        regex = r'\\b(?:' + '|'.join(val) + r')\\b'\n",
    "        pattern = re.compile(regex, flags=re.IGNORECASE)\n",
    "        patterns[key] = pattern\n",
    "\n",
    "def mf_vector(text: str) -> np.ndarray:\n",
    "    if not text.strip():\n",
    "        return np.zeros(4)\n",
    "    total = 1\n",
    "    if len(text.split()) != 0: total = len(text.split())\n",
    "    ratios = []\n",
    "    for key in dims:\n",
    "        matches = patterns[key].findall(text)\n",
    "        ratio = len(matches) / total\n",
    "        ratios.append(ratio)\n",
    "    return np.array(ratios)\n",
    "\n",
    "X = np.vstack(df['request_text'].fillna('').map(mf_vector))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=SIZE, random_state=SEED, stratify=STRATIFY)\n",
    "model_4 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='linear', C=10, class_weight='balanced', probability=True, random_state=42)).fit(X_train, y_train)\n",
    "pred = model_4.predict(X_test)\n",
    "prob = model_4.predict_proba(X_test)[:,1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6393be1d-d778-42a7-9c03-3000baa65300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4 accuracy 0.7306338028169014 precision 0.11764705882352941 recall 0.014285714285714285 F1 0.025477707006369428 specificity 0.9649532710280374 AUC 0.4714869826435246\n"
     ]
    }
   ],
   "source": [
    "modelnumber='Model_4'\n",
    "print_results(modelnumber, y_test,pred,prob, tn, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a17de64d-493f-4d34-80d6-cfcef414d3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4 accuracy 0.7306338028169014 precision 0.11764705882352941 recall 0.014285714285714285 F1 0.025477707006369428 specificity 0.9649532710280374 AUC 0.4714869826435246\n"
     ]
    }
   ],
   "source": [
    "modelnumber='Model_4'\n",
    "print_results(modelnumber, y_test,pred,prob, tn, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
